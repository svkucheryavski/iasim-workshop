{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geometric transformations\n",
    "\n",
    "Now we know that every pixel has two properties:\n",
    "\n",
    "1. Coordinate of the pixel in an image grid (row, column) or (y, x).\n",
    "2. Intensity of the pixel (either one value or vector of values).\n",
    "\n",
    "In this class we will discuss transformation of coordinates of the pixels. Image transformation implies producing a new image based on the current one. Python makes it easy to perform basic transformations on digital images either manually, by doing manipulations with arrays, or by using methods from dedicated libraries.\n",
    "\n",
    "Some common geometric operations include:    \n",
    "\n",
    "*  Cropping, flipping, merging\n",
    "*  Resizing/subsampling\n",
    "*  Rotation \n",
    "*  Shearing\n",
    "\n",
    "There are also more advance transformations, e.g. projective which we will not touch upon. In addition to that you can unfold and refold images to data matrix which we will briefly discuss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Image transformations by arrays manipulations\n",
    "\n",
    "Let's start with cropping. *Cropping* involves removing parts of the image to focus on a particular area of interest, often used for removing unwanted elements in the image. Cropping is easy to do by subsetting rows and columns of the array with color intensities.\n",
    "\n",
    "Let's load the apple image again and convert it to NumPy array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "img = Image.open(\"datasets/Apples.jpg\")\n",
    "img_arr = np.array(img)\n",
    "img_arr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's split the image to two, so the first one contains only the red apples and the second one contains only the green ones. \n",
    "\n",
    "We know that the width of the original image is 800 pixels (the array has 800 columns), so we can simply take a subset of the columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take columns with indices from 0 to 399 (first 400 columns)\n",
    "red_apples = img_arr[:, 0:400, :]\n",
    "\n",
    "(img_arr.shape, red_apples.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# take columns with indices from 400 to 799 (last 400 columns)\n",
    "green_apples = img_arr[:, 400:800]\n",
    "\n",
    "(img_arr.shape, green_apples.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the cropped images\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(red_apples)\n",
    "plt.title(\"Red\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(green_apples)\n",
    "plt.title(\"Green\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It works, but we can see some red apples among the green ones. Let's crop the image starting from column 500 instead, plus skip the first 150 rows. Let's do the same also for the red apples in order to let both images having the same size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take rows with indices from 150 to 599 and columns with indices from 0 to 299 (first 300 columns)\n",
    "red_apples = img_arr[150:600, 0:300]\n",
    "red_apples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take columns with indices from 500 to 799 (last 300) and the same rows\n",
    "green_apples = img_arr[150:600, 500:800]\n",
    "green_apples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the cropped images\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(red_apples)\n",
    "plt.title(\"Red\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(green_apples)\n",
    "plt.title(\"Green\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks better! In fact, if an index involves the last row or the last column we can skip it and leave its place empty. Same in case if an index starts with the first (zero) row or column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same operation but without explicit declaration of the last row and the first column\n",
    "red_apples = img_arr[150:, :300]\n",
    "\n",
    "# same operation but without explicit declaration of the last row and the last column\n",
    "green_apples = img_arr[150:, 500:]\n",
    "\n",
    "# show the cropped images\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(red_apples)\n",
    "plt.title(\"Red\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(green_apples)\n",
    "plt.title(\"Green\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can also *flip* the images vertically or horizontally (or both) by changing order of the rows and columns. In this case we need to provide an extra element in the sequence of indices, which will be the step. If we use step -1 we take the last row and make it first, then take the row before the last and make it the second etc. \n",
    "\n",
    "Here is how it works with rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flip image vertically by reordering rows of pixels in reverse order\n",
    "red_apples_vf = red_apples[::-1, :]\n",
    "\n",
    "# show the cropped images\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(red_apples)\n",
    "plt.title(\"Red (original)\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(red_apples_vf)\n",
    "plt.title(\"Red (flipped vertically)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a code which will also flip red apples vertically and both vertically and horizontally. Show a figure with all four images together — the original one and the three flipped ones (vertical, horizontal and both)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# place your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "If two (or more) images are represented by arrays with the same number of rows, columns or both, they can be merged into a new image. You can merge arrays (and hence the corresponding images) by stacking the vertically or horizontally. Here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "more_apples = np.hstack((red_apples, red_apples, red_apples))\n",
    "plt.imshow(more_apples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can make a sequence of stacks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "even_more_apples = np.vstack((more_apples, more_apples))\n",
    "plt.imshow(even_more_apples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is another example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the crops again\n",
    "red_apples = img_arr[150:, :300]\n",
    "green_apples = img_arr[150:, 500:]\n",
    "\n",
    "# flip the images both vertically and horizontally\n",
    "red_apples_flipped = red_apples[::-1, ::-1]\n",
    "green_apples_flipped = green_apples[::-1, ::-1]\n",
    "\n",
    "# stack the images horizontally\n",
    "img_top = np.hstack((red_apples, green_apples_flipped))\n",
    "img_bottom = np.hstack((green_apples, red_apples_flipped))\n",
    "\n",
    "# stack the previous results vertically\n",
    "img = np.vstack((img_top, img_bottom))\n",
    "\n",
    "# show the result\n",
    "plt.imshow(img)\n",
    "\n",
    "# show the dimension of the new image\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally you can also transpose an image — flipping it along its main diagonal. Here is illustration from [Wikipidea](https://en.wikipedia.org/wiki/Transpose):\n",
    "\n",
    "<img src=\"illustrations/Matrix_transpose.gif\" style=\"width:200px\" >\n",
    "\n",
    "Transposition can be also made by rotation of the image by 90 degrees and reversing the columns. In other words it simply makes rows as columns and columns as rows. \n",
    "\n",
    "Because we have 3D array (with three color channels) we need to tell NumPy explicitly how to transpose it. Because rows is the first dimension (with index 0), columns is the second dimension (with index 1) and color channels is the third dimension (with index 2), we define the new transposition of rows and columns by swapping their indices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transpose image array\n",
    "img_transposed = img.transpose((1, 0, 2))\n",
    "img_transposed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the result\n",
    "plt.imshow(img_transposed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to change the code above to crop the image for focusing on the green apples instead.\n",
    "\n",
    "**The transformation is not the same as rotation. Think what you need to combine the transposition with in order to rotate the image by 90, -90 or 180 degrees?** Try your ideas here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# place your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unfolding, refolding and scatter plots\n",
    "\n",
    "One can think about a color image as a dataset, where pixels are samples (objects) and color channels are variables (columns) as it is shown below:\n",
    "\n",
    "<img src=\"illustrations/image-as-data.png\" style=\"width:700px\" >\n",
    "\n",
    "The operation of transforming the color image represented as 3D array to 2D data matrix is called *unfolding*. The opposite operation is usually called refolding.\n",
    "\n",
    "Let's load the *Apples* image, unfold it and make a scatter plot where each pixel will be a point in cartesian space. Let's make such plot for red and green color channels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image and convert to NumPy array\n",
    "img = Image.open(\"datasets/Apples.jpg\")\n",
    "img_arr = np.array(img)\n",
    "\n",
    "img_arr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the image contains almost half of a million pixels, which will be quite heavy to process. Let's downsample the image by taking every fourth row and every fourth column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_arr_small = img_arr[::4, ::4, :]\n",
    "img_arr_small.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should be doable, let's unfold first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's get every dimension to separate variable\n",
    "height, width, nchannels = img_arr_small.shape\n",
    "\n",
    "# compute total number of pixels\n",
    "npixels = height * width\n",
    "\n",
    "# unfold array to dataset\n",
    "img_data = img_arr_small.reshape((npixels, nchannels))\n",
    "img_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's look at top rows\n",
    "img_data[0:5, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make plot for red (1st channel) vs green (2nd channel)\n",
    "plt.scatter(img_data[:, 0], img_data[:, 1], marker = \".\")\n",
    "plt.xlabel(\"Red\")\n",
    "plt.xlabel(\"Green\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We can use color of pixels to colorize the points (will be a bit slower!):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(img_data[:, 0], img_data[:, 1], marker = \".\", edgecolors=None, color = img_data/255)\n",
    "plt.xlabel(\"Red\")\n",
    "plt.ylabel(\"Green\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another possibility is to compute density for every point on the plot — how many pixels are around. In this case we need to install another useful package, `scipy`, which contains a lot of useful functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's compute the density and use it for color coding (it will take some time!):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "# select only relevant columns and transpose selection\n",
    "dens_data = img_data[:, 0:2].T\n",
    "\n",
    "# calculate the point densities\n",
    "dens = gaussian_kde(dens_data)(dens_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a plot using plot densities for color gradient\n",
    "plt.scatter(img_data[:, 0], img_data[:, 1], marker = \".\", edgecolors=None, c = dens)\n",
    "plt.xlabel(\"Red\")\n",
    "plt.ylabel(\"Green\")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By the way, the computed density values can be refolded to one-channel image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dens_img = dens.reshape((height, width))\n",
    "plt.imshow(dens_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can even make Principal Component Analysis (via Singular Value Decomposition) and show scores as images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import SVD method from numpy\n",
    "from numpy.linalg import svd\n",
    "\n",
    "# mean center the columns\n",
    "img_data_centered = img_data - img_data.mean(axis = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# computed SVD\n",
    "U, S, V = svd(img_data_centered, full_matrices=False)\n",
    "\n",
    "# compute scores\n",
    "T = np.dot(U, np.diag(S))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# refold matrix scores into image\n",
    "score_img = T.reshape((height, width, nchannels))\n",
    "\n",
    "# show the scores for PC1\n",
    "plt.imshow(score_img[:, :, 0])\n",
    "plt.title(\"PC1\")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the scores for PC1 with thresholding\n",
    "plt.imshow(score_img[:, :, 0] < 0)\n",
    "plt.title(\"PC1\")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And of course you can use the result of thresholding as a mask and combine it with the original image. However in this case you need to use transposed arrays to let NumPy do multiplication of 3D array and 2D array correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (score_img[:, :, 0] < 0)\n",
    "img_masked = img_arr_small.T * mask.T\n",
    "\n",
    "# show the scores for PC1 with thresholding\n",
    "plt.imshow(img_masked.T)\n",
    "plt.title(\"PC1\")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Image transformations in PIL\n",
    "\n",
    "Now let's learn how to do transformations in PIL. All transformations can be actually done manually by using NumPy arrays, but it will require a lot of code. So we will reuse the code already written by the PIL/Pillow developers. First of all you can do all operations we discussed above in PIL as well. \n",
    "\n",
    "\n",
    "### Cropping and flipping\n",
    "\n",
    "Let's load the apple image again and crop it to focus on the part with red apples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(\"datasets/Apples.jpg\")\n",
    "\n",
    "# defining the bounding box (left, upper, right, lower) for red apples part\n",
    "box_red = (0, 0, 300, 600)\n",
    "\n",
    "# crop the image into new ones)\n",
    "img_red = img.crop(box_red)\n",
    "\n",
    "# show the cropped image\n",
    "img_red"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also flip images in PIL as shown the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_flipped = img.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "\n",
    "img_flipped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resizing\n",
    "\n",
    "Here is how to resize the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definig the new size in pixels (width, height)\n",
    "new_size = (400, 300)\n",
    "\n",
    "resized_img = img.resize(new_size)\n",
    "\n",
    "resized_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep in mind that resizing does not keep the correct aspect ratio, it is your responsibility. Otherwise you can make some distortions like the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definig the new size which does not keep the correct aspect ratio\n",
    "new_size = (400, 100)\n",
    "\n",
    "resized_img = img.resize(new_size)\n",
    "\n",
    "resized_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rotation\n",
    "\n",
    "Rotation alters the orientation of an image by a specified angle, allowing for adjustments to the image's orientation or alignment. It's useful for correcting skewed images or achieving desired visual effects. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rotation the image by 40 degrees clockwise\n",
    "rotated_image = img.rotate(40)\n",
    "\n",
    "rotated_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the rotated image has the same size as the original. You can change this if you add additional argument to the `rotate()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rotation the image by 40 degrees clockwise and resize\n",
    "rotated_image = img.rotate(40, expand=1)\n",
    "\n",
    "rotated_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpolation\n",
    "\n",
    "Any transformation which changes the position of pixels requires additional operation — *interpolation*. The idea is as follows. The image is always a rectangle with fixed number of pixels. But when you e.g. rotate the pixels, they do not match the grid:\n",
    "\n",
    "<img src=\"illustrations/interp1.png\" width=\"400px\">\n",
    "\n",
    "Here is another illustration. \n",
    "\n",
    "<img src=\"illustrations/interp2.png\" width=\"700px\">\n",
    "\n",
    "The black squares represent the grid of pixels on the final image. The color rectangles represent the old pixels after rotation. As you can see they do not match. So what we need to do is to compute intensities of the black pixels by taking into account the intensities of the colored pixels around.\n",
    "\n",
    "Let's show the same but making the old and the new pixels round and more sparse for the sake of clarity:\n",
    "\n",
    "<img src=\"illustrations/interp3.png\" width=\"400px\">\n",
    "\n",
    "And our goal is to compute the intensity of the bold black pixel in the middle. There are three main possibilities (other ways also exist but will not be considered here):\n",
    "\n",
    "**Nearest neighbor**\n",
    "\n",
    "Simply takes the intensity of the closest pixel:\n",
    "\n",
    "<img src=\"illustrations/interp-nn.png\" width=\"400px\">\n",
    "\n",
    "**Bilinear interpolation**\n",
    "\n",
    "Takes four pixels around:\n",
    "\n",
    "<img src=\"illustrations/interp-bl.png\" width=\"400px\">\n",
    "\n",
    "Fits their intensities using a set of linear functions and then computes the new intensity based on the interpolations:\n",
    "\n",
    "<img src=\"illustrations/interp-bl2.png\" width=\"700px\">\n",
    "\n",
    "**Bicubic interpolation**\n",
    "\n",
    "Takes 16 pixels around:\n",
    "\n",
    "<img src=\"illustrations/interp-bc.png\" width=\"400px\">\n",
    "\n",
    "Fits their intensities with a set of cubic polynomials and then computes the new intensity based on the functions (not shown here).\n",
    "\n",
    "The simplest and the fastest is *nearest neighbor* method and this is also the default ones. If you want to use other methods, simply specify additional parameter to the transformation function as it is shown in the example below:\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rotation the image by 40 degrees clockwise and resize using bilinear interpolation\n",
    "rotated_image = img.rotate(40, expand=1, resample=Image.Resampling.BILINEAR)\n",
    "\n",
    "rotated_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For high resolution image with many pixels the difference is barely visible by a naked eye but for small images it can be crucial. See an example below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a small crop of the original image\n",
    "img_small = img.crop([100, 100, 180, 180])\n",
    "img_small.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# increase size of the cropped image using three different methods\n",
    "img_resized_nn = img_small.resize((400, 400), resample=Image.Resampling.NEAREST)\n",
    "img_resized_bl = img_small.resize((400, 400), resample=Image.Resampling.BILINEAR)\n",
    "img_resized_bc = img_small.resize((400, 400), resample=Image.Resampling.BICUBIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# investigate the images one by one\n",
    "img_resized_nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shearing and other transformations\n",
    "\n",
    "You can also distort the images by applying geometric transformation which changes the coordinates of the pixels so they do not match the original coordinate grid. One of the examples of such distortion is *[shearing](https://en.wikipedia.org/wiki/Shear_mapping)*.\n",
    "\n",
    "Shearing distorts the shape of an image along one axis by shifting each point by an amount proportional to its distance from a particular axis. This transformation introduces a \"sheared\" appearance, useful for creating unique visual effects or correcting perspective distortions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the shearing factor\n",
    "shear_factor = 0.1\n",
    "\n",
    "# shearing the image horizontally\n",
    "sheared_image = img.transform(img.size, Image.AFFINE, (1, shear_factor, 0, 0, 1, 0))\n",
    "\n",
    "sheared_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method `transform` can apply any geometric transformation to the pixels. Second argument of the method, `Image.AFFINE`, \"tells\" that the transformation should be [affine](https://en.wikipedia.org/wiki/Affine_transformation). Affine transformation computes new coordinates of every pixel $(x', y')$ as a linear combination of its old coordinates $(x, y)$:\n",
    "\n",
    "$x' = ax + by + c$\n",
    "\n",
    "$y' = dx + ey + f$\n",
    "\n",
    "So to apply a transformation, you simply need to provide all six coefficients in form of a tuple: `(a, b, c, d, e, f)`. For example, coefficients `(1, 0, 0, 0, 1, 0)` does not change any coordinates, this is an identity transformation.\n",
    "\n",
    "And what we did above we applied the following transformation:\n",
    "\n",
    "$x' = x + sy$\n",
    "\n",
    "$y' = y$\n",
    "\n",
    "Where $s$ was equal to 0.1. So new x-coordinate depends on the y-coordinate of the pixels, while y-coordinates do not change. Because y-coordinates of image pixels start from the top and increase to the bottom, we see a bigger shift for the bottom pixels. The larger shearing factor will be the larger shift.\n",
    "\n",
    "Now we can implement the vertical sheering:\n",
    "\n",
    "$x' = x$\n",
    "\n",
    "$y' = sx + y$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the shearing factor\n",
    "shear_factor = 0.1\n",
    "\n",
    "# shearing the image vertically\n",
    "sheared_image = img.transform(img.size, Image.AFFINE, (1, 0, 0, shear_factor, 1, 0))\n",
    "\n",
    "sheared_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And in both directions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the shearing factor\n",
    "shear_factor = 0.1\n",
    "\n",
    "# shearing the image vertically\n",
    "sheared_image = img.transform(img.size, Image.AFFINE, (1, shear_factor, 0, shear_factor, 1, 0))\n",
    "\n",
    "sheared_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to play with the sheering factor and see how it affects the outcome. \n",
    "\n",
    "You probably wonder why distort the images? Well in fact these kind of transformations are mostly used to do the opposite — remove the distortion introduced e.g. by camera or other obstacles. But sometimes distortion is also a way to enrich the image dataset in order to train a good model, which we will discuss in the last class."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
