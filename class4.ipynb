{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with hyperspectral images\n",
    "\n",
    "In this class we will learn briefly how to work with hyperspectral images in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load images from MATLAB data files\n",
    "\n",
    "If a hyperspectral image is stored as MATLAB data file (`.mat`) it can be loaded using package `scipy` which we have already installed in one of the previous classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In folder `dataset` there is a file `emulsion.mat` with a famous Raman spectral image of oil in water emulsion. It is saved as array with name `X`. Let's load it: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import function which lets load MATLAB data\n",
    "from scipy.io import loadmat\n",
    "\n",
    "# read the file and save the result to dictionary \"d\"\n",
    "d = loadmat('datasets/emulsion.mat')\n",
    "\n",
    "# check which elements this dictionary contains\n",
    "d.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, indeed the dictionary contains object with name `X`. Let's extract the object and check its size assuming that it is a NumPy array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_arr = d[\"X\"]\n",
    "img_arr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And it is indeed. As expected, the image has size of 60x60 pixels and 253 channels with Raman intensities at different wavenumbers. Let's show intensity at channel 100 as a pseudocolor image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(img_arr[:, :, 100])\n",
    "plt.title(\"Channel 100\")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It works. If necessary you can reshape the image 3D array to 2D array with rows corresponding to pixels. This let's you work with the image as conventional dataset and e.g. make a line plot with spectra:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows, ncols, nchannels = img_arr.shape\n",
    "npixels = nrows * ncols\n",
    "\n",
    "X = img_arr.reshape((npixels, nchannels))\n",
    "\n",
    "plt.plot(X.T)\n",
    "plt.xlabel(\"Spectral channels\")\n",
    "plt.ylabel(\"Intensity, A.U.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's normalize every spectrum to unit length (L2-norm):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def l2norm(x):\n",
    "    return x / np.sqrt(np.sum(x**2))\n",
    "\n",
    "X_norm = np.apply_along_axis(l2norm, 1, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the intensity of the spectra to confirm the normalization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X_norm.T)\n",
    "plt.xlabel(\"Spectral channels\")\n",
    "plt.ylabel(\"Intensity, A.U.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like this is not the best preprocessing method for this data, bit let's continue anyway and reshape the new preprocessed spectra back to spectral image and show the intensity map for channel 100 again. We will show both the original data and the preprocessed data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_arr_norm = X_norm.reshape((60, 60, 253))\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(img_arr[:, :, 100])\n",
    "plt.title(\"Channel 100 (original)\")\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(img_arr_norm[:, :, 100])\n",
    "plt.title(\"Channel 100 (normalized)\")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I you want to apply various image transformations to the hyperspectral images there are two main options:\n",
    "\n",
    "1. Use more advanced library Open CV which works with NumPy array directly.\n",
    "2. Process every channel separately as a PIL grayscale image.\n",
    "\n",
    "Here is an example how to use the second option to upscale the emulsion image and rotate it by 90 degrees:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# get dimensions of the original image\n",
    "nrows, ncols, nchannels = img_arr.shape\n",
    "\n",
    "# compute size of new image\n",
    "# because we plan to rotate it, rows and cols are swapped\n",
    "# but in this case it is not needed as they are equal\n",
    "ncols_new = nrows * 2\n",
    "nrows_new = ncols * 2\n",
    "\n",
    "# prepare array for the new image\n",
    "img_arr_new = np.zeros((nrows_new, ncols_new, nchannels))\n",
    "\n",
    "# loop to process each channel separately\n",
    "for i in range(0, nchannels):\n",
    "    img = Image.fromarray(img_arr[:, :, i])     # get the channel and convert it to PIL Image\n",
    "    img = img.resize((ncols_new, nrows_new))    # resize the image\n",
    "    img = img.rotate(90, expand=True)                        # rotate the image by 90 degrees\n",
    "    img_arr_new[:, :, i] = np.array(img)        # convert it back to NumPy array\n",
    "\n",
    "plt.imshow(img_arr_new[:, :, 100])\n",
    "plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with ENVI images\n",
    "\n",
    "In order to load hyperspectral images saved in other popular format, ENVI, we will need another library. There are several possibilities in this case:\n",
    "\n",
    "2. [GDAL](https://gdal.org/index.html) — a translator library for raster and vector geospatial data formats.  \n",
    "3. A bit outdated, but still functional and more simple package, [Spectral Python](http://www.spectralpython.net) (last release 2/10/2022).\n",
    "\n",
    "There is also [HypeSpy](https://hyperspy.org/index.html) — a Python framework for exploring, visualizing and analyzing multi-dimensional data, which provides a lot of other possibilities in addition to simply load spectra files.\n",
    "\n",
    "Below we will try the last simple option to get the hyperspectral data from ENVI format to NumPy array. Let's first install the library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install spectral"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "In the folder `dataset` there is another folder with name `tablets` which contains image of tablets in ENVI format. There are three images: the one of tablet as well as the dark and the white references. Let's load, correct, and visualize it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spectral.io import envi\n",
    "\n",
    "# open each image by providing path to header file (.hdr) and file with data values (.raw)\n",
    "dark_ref = envi.open('datasets/tablets/Tablets-darkref.hdr','datasets/tablets/Tablets-darkref.raw')\n",
    "white_ref = envi.open('datasets/tablets/Tablets-whiteref.hdr', 'datasets/tablets/Tablets-whiteref.raw')\n",
    "img_ref = envi.open('datasets/tablets/Tablets.hdr','datasets/tablets/Tablets.raw')\n",
    "\n",
    "# get information about spectral bands\n",
    "bands = img_ref.bands.centers\n",
    "bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the image data and convert to NumPy array\n",
    "\n",
    "white_img = np.array(white_ref.load())\n",
    "dark_img = np.array(dark_ref.load())\n",
    "img = np.array(img_ref.load())\n",
    "\n",
    "(white_img.shape, dark_img.shape, img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the white and dark references are obtained for 100 lines not for 337 as the original image. What we can stack several images together to meat the required size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "white_img_full = np.vstack((white_img, white_img, white_img, white_img[:37, :, :]))\n",
    "white_img_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dark_img_full = np.vstack((dark_img, dark_img, dark_img, dark_img[:37, :, :]))\n",
    "dark_img_full.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact it was not necessary as in this case we could simply take only first row of the dark and the white reference images, because the images was acquired using [pushbroom scanner](https://en.wikipedia.org/wiki/Push_broom_scanner).\n",
    "\n",
    "Let's look at the images before correction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30, 10))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(dark_img_full[:, :, 100])\n",
    "plt.colorbar()\n",
    "plt.title(\"Dark\")\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(white_img_full[:, :, 100])\n",
    "plt.colorbar()\n",
    "plt.title(\"White\")\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(img[:, :, 100])\n",
    "plt.colorbar()\n",
    "plt.title(\"Raw image\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute a difference between the dark and the white images and replace column with zeros by ones to avoid division by zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = (white_img_full - dark_img_full)\n",
    "diff[diff == 0] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can apply correction and look at the corrected image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct the image by subtracting dark reference and dividing by difference between\n",
    "# dark and white references\n",
    "corrected_img = (img - dark_img_full) / diff\n",
    "\n",
    "# show the image\n",
    "plt.imshow(corrected_img[:, :, 100])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's apply a mask:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = corrected_img[:, :, 100] > 0.4\n",
    "\n",
    "# ! this will not work\n",
    "masked_img = corrected_img * mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above is an attempt to process each channel using built in broadcasting option in NumPy, which lets avoid the loops. However it does not work because the dimension we broadcast through is the last one. We can fix this by swap the dimensions (and the return them back):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_img = corrected_img.transpose((2, 0, 1)) * mask\n",
    "masked_img = masked_img.transpose((1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(30, 10))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(corrected_img[:, :, 100])\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(mask)\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(masked_img[:, :, 100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's all, folks! :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
